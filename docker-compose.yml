version: '3.8'

services:
  # AI Transcripts Analyzer API
  api:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: ai-transcripts-analyzer
    restart: unless-stopped
    ports:
      - '3000:3000'
    environment:
      - NODE_ENV=production
      - PORT=3000
      # OpenAI Configuration
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
    volumes:
      # Mount sample files
      - ./sample:/usr/src/app/sample:ro
      # Optional: Mount logs directory
      - ./logs:/usr/src/app/logs
    healthcheck:
      test:
        [
          'CMD',
          'wget',
          '--quiet',
          '--tries=1',
          '--spider',
          'http://localhost:3000/api/transcripts/statistics',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
